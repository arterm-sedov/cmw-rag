# Agent Mode Update: tool_choice Parameter

## Date
November 2, 2025

## Overview
Updated the agent implementation to use the `tool_choice` parameter for forced tool execution instead of relying on system prompt instructions. Also switched to using the standard `SYSTEM_PROMPT` from `prompts.py`.

## Changes Made

### 1. Tool Forcing Mechanism

**Before** (System Prompt Approach):
```python
system_prompt = (
    "You are a helpful assistant for Comindware Platform documentation. "
    "You MUST ALWAYS call the retrieve_context tool to search the knowledge base "
    "before answering ANY question. Never answer without searching first."
)

agent = create_agent(
    model=model,
    tools=[retrieve_context],
    system_prompt=system_prompt,
)
```

**After** (`tool_choice` Approach):
```python
from rag_engine.llm.prompts import SYSTEM_PROMPT

# Bind tools with forced execution
model_with_tools = base_model.bind_tools(
    [retrieve_context],
    tool_choice="retrieve_context"  # Forces this tool to be called
)

agent = create_agent(
    model=model_with_tools,
    tools=[retrieve_context],
    system_prompt=SYSTEM_PROMPT,  # Standard Comindware Platform prompt
)
```

### 2. System Prompt

**Before**: Custom simplified prompt for agent mode
**After**: Standard `SYSTEM_PROMPT` from `prompts.py` containing:
- Full Comindware Platform documentation assistant role
- Terminology guidelines
- Citation format rules
- Answer structure guidelines
- AI-generated content disclaimer
- Multi-perspective reasoning instructions

## Benefits

### 1. More Reliable Tool Forcing
- **`tool_choice` parameter** is the [official LangChain mechanism](https://docs.langchain.com/oss/python/langchain/models#tool-calling) for forcing tool execution
- More reliable than prompt-based instructions
- Model cannot ignore or misinterpret tool requirements

### 2. Consistent System Behavior
- Agent mode now uses the **same system prompt** as direct retrieval mode
- Same answer quality, formatting, and citation style
- Maintains all terminology guidelines and constraints
- Users get consistent experience regardless of mode

### 3. Better Maintainability
- One source of truth for system prompt (`prompts.py`)
- Changes to prompt automatically apply to agent mode
- No prompt duplication or drift between modes

## Implementation Details

### Model Binding
According to [LangChain documentation](https://docs.langchain.com/oss/python/langchain/models#tool-calling):

```python
model_with_tools = model.bind_tools(
    [tool_list],
    tool_choice="tool_name"  # Forces specific tool
)
```

This approach:
- Works with Gemini, OpenAI, Anthropic, and other providers
- Ensures tool is called on every invocation
- More robust than prompt-based forcing

### Test Updates
Updated 2 tests to verify:
- `bind_tools()` is called with `tool_choice="retrieve_context"`
- Standard `SYSTEM_PROMPT` is used (contains "Comindware Platform", `<role>` tags)
- Model with tools is passed to `create_agent()`

**Result**: 10/10 tests passing ‚úÖ

## Comparison

| Aspect | Before | After |
|--------|--------|-------|
| **Tool Forcing** | System prompt instructions | `tool_choice` parameter |
| **Reliability** | Depends on LLM following instructions | Guaranteed by framework |
| **System Prompt** | Custom simplified prompt | Standard `SYSTEM_PROMPT` |
| **Answer Quality** | Good | Excellent (full prompt) |
| **Maintainability** | Duplicate prompts | Single source of truth |
| **LangChain Compliance** | Works but not idiomatic | Official pattern |

## References

- [LangChain Models - Tool Calling](https://docs.langchain.com/oss/python/langchain/models#tool-calling)
- [LangChain Tools Documentation](https://docs.langchain.com/oss/python/langchain/tools)
- [LangChain GitHub Docs](https://github.com/langchain-ai/docs/blob/main/src/oss/langchain/models.mdx)

## Code Changes

### Files Modified
1. `rag_engine/api/app.py`:
   - Updated `_create_rag_agent()` to use `bind_tools()` with `tool_choice`
   - Import `SYSTEM_PROMPT` from `prompts.py`
   
2. `rag_engine/tests/test_agent_handler.py`:
   - Updated `test_create_agent_gemini()` to verify `bind_tools()` call
   - Updated `test_system_prompt_uses_standard_prompt()` to check for standard prompt elements

3. `README.md`:
   - Updated feature list to mention `tool_choice` parameter
   - Added reference to LangChain documentation

### Lines Changed
- ~15 lines in `app.py`
- ~30 lines in test file
- ~5 lines in README

## Validation

```bash
pytest rag_engine/tests/test_agent_handler.py -v
```

**Result**:
```
‚úÖ 10/10 tests passing
‚úÖ 100% coverage for test_agent_handler.py
‚úÖ No linting errors
```

## Metadata Messages (Gradio Integration)

### Implementation
Added real-time tool execution status messages following the [Gradio agents pattern](https://www.gradio.app/4.44.1/guides/agents-and-tool-usage#the-metadata-key):

**On Tool Start:**
```python
status_msg = {
    "role": "assistant",
    "content": "",
    "metadata": {"title": "üîç Searching information in the knowledge base"}
}
messages.append(status_msg)
```

**On Tool Completion:**
```python
completion_msg = {
    "role": "assistant",
    "content": "",
    "metadata": {"title": f"‚úÖ Found {articles_count} articles"}
}
messages.append(completion_msg)
```

### User Experience
- **Before tool call**: User sees "üîç Searching information in the knowledge base" (collapsible)
- **After tool call**: User sees "‚úÖ Found X article(s)" (collapsible)
- **During answer**: Streaming response with citations

This provides visual feedback that the agent is working, improving perceived performance and transparency.

### References
- [Gradio Agents & Tool Usage Guide](https://www.gradio.app/4.44.1/guides/agents-and-tool-usage#the-metadata-key)
- [LangChain Middleware for Status Messages](https://docs.langchain.com/oss/python/langchain/middleware)

## Conclusion

The agent implementation now follows [LangChain's official best practices](https://docs.langchain.com/oss/python/langchain/models#tool-calling) for tool forcing and uses the standard Comindware Platform system prompt. This provides:

1. **More reliable** tool execution via `tool_choice` parameter
2. **Better answer quality** with full system prompt
3. **Visual feedback** with Gradio metadata messages
4. **Easier maintenance** with single source of truth
5. **Full compliance** with LangChain and Gradio patterns

The change is **backward compatible** - users with `USE_AGENT_MODE=true` will automatically benefit from the improved implementation.

